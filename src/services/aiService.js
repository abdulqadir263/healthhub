/**
 * AI Service - Generalized AI Provider Interface
 * 
 * This service provides a unified interface for multiple AI providers.
 * Configure your preferred provider in the .env file using VITE_AI_PROVIDER.
 * 
 * Supported providers:
 * - gemini (Google Generative AI)
 * - openai (OpenAI)
 * - anthropic (Anthropic Claude)
 * 
 * To add a new provider:
 * 1. Add the provider configuration in .env.example
 * 2. Implement the provider-specific functions in this file
 * 3. Register the provider in the providers object
 */

import { GoogleGenerativeAI } from '@google/generative-ai';

// Get current AI provider from environment
const AI_PROVIDER = import.meta.env.VITE_AI_PROVIDER || 'gemini';

// Provider-specific implementations
const providers = {
  gemini: {
    generateResponse: geminiGenerateResponse,
    generateResponseWithImage: geminiGenerateResponseWithImage,
    chat: geminiChat,
  },
  openai: {
    generateResponse: openaiGenerateResponse,
    generateResponseWithImage: openaiGenerateResponseWithImage,
    chat: openaiChat,
  },
  anthropic: {
    generateResponse: anthropicGenerateResponse,
    generateResponseWithImage: anthropicGenerateResponseWithImage,
    chat: anthropicChat,
  },
};

// =============================================================================
// GEMINI PROVIDER IMPLEMENTATION
// =============================================================================

let genAI = null;
function getGeminiClient() {
  if (!genAI && import.meta.env.VITE_GEMINI_API_KEY) {
    genAI = new GoogleGenerativeAI(import.meta.env.VITE_GEMINI_API_KEY);
  }
  return genAI;
}

async function geminiGenerateResponse(prompt, context = '') {
  const client = getGeminiClient();
  if (!client) throw new Error('Gemini API key not configured');
  
  const model = client.getGenerativeModel({ 
    model: import.meta.env.VITE_GEMINI_MODEL || 'gemini-2.0-flash-exp'
  });

  const fullPrompt = context ? `${context}\n\n${prompt}` : prompt;
  const result = await model.generateContent(fullPrompt);
  const response = await result.response;
  return response.text();
}

async function geminiGenerateResponseWithImage(prompt, imageFile) {
  const client = getGeminiClient();
  if (!client) throw new Error('Gemini API key not configured');
  
  const model = client.getGenerativeModel({ 
    model: import.meta.env.VITE_GEMINI_MODEL || 'gemini-2.0-flash-exp'
  });

  const imageData = await fileToBase64(imageFile);
  const result = await model.generateContent([
    prompt, 
    { inlineData: { data: imageData, mimeType: imageFile.type } }
  ]);
  const response = await result.response;
  return response.text();
}

async function geminiChat(messages) {
  const client = getGeminiClient();
  if (!client) throw new Error('Gemini API key not configured');
  
  const model = client.getGenerativeModel({ 
    model: import.meta.env.VITE_GEMINI_MODEL || 'gemini-2.0-flash-exp'
  });

  const chat = model.startChat({
    history: messages.slice(0, -1).map(msg => ({
      role: msg.role === 'assistant' ? 'model' : msg.role,
      parts: [{ text: msg.content }]
    }))
  });

  const lastMessage = messages[messages.length - 1];
  const result = await chat.sendMessage(lastMessage.content);
  const response = await result.response;
  return response.text();
}

// =============================================================================
// OPENAI PROVIDER IMPLEMENTATION
// =============================================================================

async function openaiGenerateResponse(prompt, context = '') {
  const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
  if (!apiKey) throw new Error('OpenAI API key not configured');
  
  const model = import.meta.env.VITE_OPENAI_MODEL || 'gpt-4';
  const fullPrompt = context ? `${context}\n\n${prompt}` : prompt;

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      messages: [{ role: 'user', content: fullPrompt }],
    }),
  });

  if (!response.ok) {
    throw new Error(`OpenAI API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

async function openaiGenerateResponseWithImage(prompt, imageFile) {
  const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
  if (!apiKey) throw new Error('OpenAI API key not configured');
  
  const model = import.meta.env.VITE_OPENAI_MODEL || 'gpt-4-vision-preview';
  const base64Image = await fileToBase64(imageFile);

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      messages: [{
        role: 'user',
        content: [
          { type: 'text', text: prompt },
          { type: 'image_url', image_url: { url: `data:${imageFile.type};base64,${base64Image}` } }
        ],
      }],
    }),
  });

  if (!response.ok) {
    throw new Error(`OpenAI API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

async function openaiChat(messages) {
  const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
  if (!apiKey) throw new Error('OpenAI API key not configured');
  
  const model = import.meta.env.VITE_OPENAI_MODEL || 'gpt-4';

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      messages: messages.map(msg => ({
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: msg.content,
      })),
    }),
  });

  if (!response.ok) {
    throw new Error(`OpenAI API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

// =============================================================================
// ANTHROPIC PROVIDER IMPLEMENTATION
// =============================================================================

async function anthropicGenerateResponse(prompt, context = '') {
  const apiKey = import.meta.env.VITE_ANTHROPIC_API_KEY;
  if (!apiKey) throw new Error('Anthropic API key not configured');
  
  const model = import.meta.env.VITE_ANTHROPIC_MODEL || 'claude-3-opus-20240229';
  const fullPrompt = context ? `${context}\n\n${prompt}` : prompt;

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
    },
    body: JSON.stringify({
      model,
      max_tokens: 4096,
      messages: [{ role: 'user', content: fullPrompt }],
    }),
  });

  if (!response.ok) {
    throw new Error(`Anthropic API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.content[0].text;
}

async function anthropicGenerateResponseWithImage(prompt, imageFile) {
  const apiKey = import.meta.env.VITE_ANTHROPIC_API_KEY;
  if (!apiKey) throw new Error('Anthropic API key not configured');
  
  const model = import.meta.env.VITE_ANTHROPIC_MODEL || 'claude-3-opus-20240229';
  const base64Image = await fileToBase64(imageFile);

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
    },
    body: JSON.stringify({
      model,
      max_tokens: 4096,
      messages: [{
        role: 'user',
        content: [
          { type: 'text', text: prompt },
          { type: 'image', source: { type: 'base64', media_type: imageFile.type, data: base64Image } }
        ],
      }],
    }),
  });

  if (!response.ok) {
    throw new Error(`Anthropic API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.content[0].text;
}

async function anthropicChat(messages) {
  const apiKey = import.meta.env.VITE_ANTHROPIC_API_KEY;
  if (!apiKey) throw new Error('Anthropic API key not configured');
  
  const model = import.meta.env.VITE_ANTHROPIC_MODEL || 'claude-3-opus-20240229';

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
    },
    body: JSON.stringify({
      model,
      max_tokens: 4096,
      messages: messages.map(msg => ({
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: msg.content,
      })),
    }),
  });

  if (!response.ok) {
    throw new Error(`Anthropic API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.content[0].text;
}

// =============================================================================
// HELPER FUNCTIONS
// =============================================================================

async function fileToBase64(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve(reader.result.split(',')[1]);
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

function getProvider() {
  const provider = providers[AI_PROVIDER];
  if (!provider) {
    throw new Error(`Unsupported AI provider: ${AI_PROVIDER}. Supported providers: ${Object.keys(providers).join(', ')}`);
  }
  return provider;
}

// =============================================================================
// PUBLIC API - Unified interface for all providers
// =============================================================================

/**
 * Generate an AI response for a given prompt
 * @param {string} prompt - The prompt to send to the AI
 * @param {string} context - Optional context to prepend to the prompt
 * @returns {Promise<string>} The AI's response
 */
export const generateAIResponse = async (prompt, context = '') => {
  try {
    const provider = getProvider();
    return await provider.generateResponse(prompt, context);
  } catch (error) {
    console.error(`AI Provider (${AI_PROVIDER}) Error:`, error);
    throw new Error(`Failed to generate AI response: ${error.message}`);
  }
};

/**
 * Generate an AI response for a prompt with an image
 * @param {string} prompt - The prompt to send to the AI
 * @param {File} imageFile - The image file to analyze
 * @returns {Promise<string>} The AI's response
 */
export const generateAIResponseWithImage = async (prompt, imageFile) => {
  try {
    const provider = getProvider();
    return await provider.generateResponseWithImage(prompt, imageFile);
  } catch (error) {
    console.error(`AI Provider (${AI_PROVIDER}) Error:`, error);
    throw new Error(`Failed to generate AI response with image: ${error.message}`);
  }
};

/**
 * Have a conversation with the AI
 * @param {Array<{role: string, content: string}>} messages - Array of messages in the conversation
 * @returns {Promise<string>} The AI's response
 */
export const chatWithAI = async (messages) => {
  try {
    const provider = getProvider();
    return await provider.chat(messages);
  } catch (error) {
    console.error(`AI Provider (${AI_PROVIDER}) Chat Error:`, error);
    throw new Error(`Failed to chat with AI: ${error.message}`);
  }
};

/**
 * Get the current AI provider name
 * @returns {string} The current provider name
 */
export const getCurrentProvider = () => AI_PROVIDER;

/**
 * Get list of supported AI providers
 * @returns {string[]} Array of supported provider names
 */
export const getSupportedProviders = () => Object.keys(providers);
